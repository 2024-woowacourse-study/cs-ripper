**운영체제란 무엇인가?**
	- 운영체제란 시스템 자원을 관리하는 프로그램을 이야기합니다. 여기서 시스템 자원이란 프로세서, 메모리, 디스크, I/O를 말합니다.
	- 옛날엔 컴퓨터의 모든 자원을 사용자가 관리했으나, 이를 자동화 하기 위해서 운영체제가 도입되었습니다.
	- 운영체제도 그럼 일종의 프로그램인데 컴퓨터가 켜질때 어떻게 메모리에 올라가나요?
		- 운영체제는 부팅(Booting)과정을 거쳐 메모리에 로드되고 시스템 자원을 관리하기 시작합니다.
			- Booting 이란 아래와 같은 과정을 거칩니다.
			-  ROM에 있는 BIOS 혹은 UEIF 프로그램(펌웨어)을 메모리에 로드하여 실행한다.
					* **Rom** : Read-Only-Memory로 메인보드에 저장되어있고, 전원이 꺼져도 프로그램이 사라지지 않은 특징을 가짐 > rom은 완전한 read-only 일 수도 있고 firmware처럼 썻다 지웠다 할 수 있음
					* **BIOS(Basic Input/Ouput**) System으로 하드웨어를 사용 가능한 상태로 초기화하고부트로더를 찾는 역할을 함 운영체제를 메모리에 올리는 역할을 함
					* 혹은 UEFI(Unified Extensible Firmware Interface)를 불러와서 OS를 올릴 수 있음. BIOS와 다르게 UEFI로 부팅한 컴퓨터는 BIOS보다 더 많은 디스크 용량을 가질 수 있음

**커널이란 무엇인가?**
* OS안에서 실제 메모리와 프로세서를 관리하는 프로그램. 컴퓨터 하드웨어와 응용프로그램를 중간에서 관리하는 프로그램을 이야기한다.
* 유저의 응용 프로그램은 직접 하드웨어를 제어하지 않고 반드시 커널을 거쳐 실행된다. 커널이란 하드웨어를 직접적으로 관리하는 운영체제 구성하는 프로그램 이다.

**커널모드 vs 유저모드**
* CPU의 실행모드에는 2가지 모드가 있음 유저모드 커널모드
*  유저모드 : 응용 프로그램이 직접 하드웨어를 접근하지 못하는 상태로 동작하는 모드를 의미한다.
*  커널모드 : 하드웨어를 직접 접근해서 시스템 자원을 관리하는 모드를 의미함 

**시스템 콜**
* 유저모드에서 프로그램이 실행 할 때 시스템 자원이 필요할 경우 시스템 콜이 발동됨
	* 시스템 콜은 아래와 같은 요청이 들어올 때 발생함
		* 파일을 읽거나 쓸 때 
		* IO가 발생할 때(네트워크 I/O(socket), Console I/O 등등)
		* 또다른 프로세스 실행
		* 메모리 자원 할당
	* 시스템 콜의 동작방식은 아래와 같음
		* 시스템 자원을 사용해야 할 필요가 있음 위의 4가지
		* cpu측에 system call api를 요청함 
		* cpu는 커널모드로 전환하기 위해 trap 명령어를 실행
		* x86에서 trap은 int [시스템 콜 번호]로 구성됨 그럼 인터럽트와 트렙의 차이

**인터럽트 vs 트랩**
* 둘 다 실행중이던 연산을 중단하고 실행한다는 모습에서 동일
* 인터럽트는 외부 하드웨어에서 발생 (Disk I/O, 키보드 입력)
* 트랩은 CPU 내부에서 발생(0으로 나누는 예외 처리 및 System call 처리)
* 처리 방식의 차이점
	* 인터럽트 : 비동기적으로 발생하여 언제든지 CPU의 흐름을 변경
	* 트렙 : 동기적으로 소프트웨어나 CPU 내부 이벤트에 의해 발생

**DMA(Direct Memory Access)**
* 왜나왔나? 위처럼 매번 I/O 작업 시스템 콜이 일어나면 CPU가 부담될 수 밖에 없음
* CPU의 부담을 덜기 위해 각 주변장치(Disk, RAM, GPU 등)에 DMA Controller가 있다고 함 
* DMA는 하드웨어이며 각 주변장치들의 데이터 이동 작업을 CPU가 맡지 않고 DMA가 처리해줌
* CPU는 DMA에게 어떤 장치에 얼만큼의 데이터를 전송해! 라고 명령어 주면 DMA는 데이터 전송을 처리한 후에 CPU에게 인터럽트를 걸어 전송이 완료되었다고 응답하는 느낌이라고 보면 됨

**프로세스란?**
* 실행 중인 "프로그램"을 프로세스라고 함 운영체제가 프로세스를 관리함
* 프로세스는 메모리를 가짐
	* Text Area : 실행될 프로그램 코드
	* Data Area: 전역 변수 구역
	* Stack Area : 함수 안에 관리되는 지역 변수, 매개 변수, 리턴 주소, 호출되는 함수 주소 관리
	* Heap Area: 프로그래머가 동적으로 할당한 메모리 구역
* 운영체제가 관리하는 프로세스 상태 5가지
	* 생성 -> 준비 -> 실행 혹은 대기 -> 종료로 구성됨
		* 대기 : disk I/O, 사용자 I/O가 일어날 때 대기
* 프로세스 제어 블록(PCB)
	* 프로그램 실행에 필요한 정보가 들어있음
		* 다음 실행할 명령어 주소(PC)
		* PID
		* 프로세스 상태
		* 메모리 주소
		* CPU 레지스터 값

**스레드**
* 스레드란 하나의 프로세스안에서 나눌 수 있는 최소의 실행 단위를 이야기함 한 프로세스 안에는 최소 하나의 스레드가 있음
* 왜 스레드가 나오게 되었나?
	* 프로세스 하나로 컴퓨터를 관리하게 되면 여러 작업을 동시에 처리할 수 없음 ㅜㅜ
		* 키보드 입력
		* 화면 출력
		* Disk I/O
		* Network I/O
* 스레드의 장점은 프로세스 안의 메모리 데이터를 공유할 수 있음
	
**멀티스레딩**
* 한 프로세스 안에서 여러 개의 스레드를 생성하여 여러 작업을 동시에 처리하는 것을 이야기함
* 하지만, 큰 힘에는 책임이 따르는 법 여러개의 스레드가 메모리 안의 공유 자원을 쉽게 접근이 가능하니 동시에 여러 스레드가 한 자원을 접근하게 될 때 어떻게 처리할 것인가에 대해도 고민해야 할 필요가 있음
* 이럴때 생긴 개념이 쓰레드 동기화임 
	* 스레드 동기화를 적용하여 여러 스레드가 동시에 접근할 때 하나의 쓰레드가 한 공유 자원을 사용하면 다른 스레드가 접근하지 못하도록 잠금 처리를 할 수 있음 (critical section)
	* 서로 필요한 잠금에 대한 키를 가지고있고 상대 잠금이 풀릴때까지 무한정 기다리는 상황을 데드락이라고 함
	* 스레드 동기화가 일어나지 않아 데이터의 결과를 알 수 없는 상태를 경쟁 상태(race condition)이라고 함
* 스레드가 많을 수록 좋지 않음 스레드가 동시에 여러 작업을 처리하는 것 같아보여도 CPU에는 한 번에 하나의 작업을 처리함 스레드작업이 마치고 다른 스레드 작업으로 전환하는 것을 context switching이라고 함

**멀티 프로세싱**
* 멀티 스레딩 처럼 멀티프로세싱은 여러 프로세스가 여러 작업들을 동시에 처리하는 것을 의미함
* 스레드와 다르게 각 프로세스는 메모리를 공유하지 않으므로 프로세스 간의 작업을 공유하기 위한 방법이 마련되어야 함
	* IPC(Inter-Process-Communication)
		* 파이프 방식: 단 방향으로 주로 부모와 자식프로세스 간에 자원을 전달하는 방식
		* 공유 메모리 방식 : 특정 메모리 공간을 공유하여 다른 프로세스들이 사용할 수 있게 만드는 방식
		* Message Queue : Queue에 데이터를 저장하고 다른 프로세스들이 해당 데이터를 가져와서 공유하는 방식
		* 소켓(Socket): 네트워크를 이용해 데이터를 전달하고 받는 방식
	
**컨텍스트 스위칭**
* 한 스레드에서 다른 스레드로 작업을 전환할 때 발생. 너무 많은 스레드를 실행할 경우 컨텍스트 스위칭 비용이 작업을 처리하는 비용보다 높아지는 현상 즉 스레싱이 발생할 수 있음
* 컨텍스트 스위칭을 하기 위해선 현재 동작하고 있는 스레드 작업 정보를 PCB(Process Control Block)에 저장
* 우선순위 값을 바탕으로 다음 작업 선정 후 실행후 위의 과정을 반복

**리눅스 스케줄러 종류**
* 리눅스는 기본 스케쥴러로 일반 프로세스는 CFS(Completely-Fair-Schedular)를 사용함
	* 이는 모든 프로세스는 CPU 자원을 공정하게 사용하도록 스케쥴링이 되어있음
		* Red-Black Tree를 활용하여 공정함을 관리함
	* 중요한 작업에 우선순위를 부여하지 않아 다양한 부하처리가 어려울 수 있음
* 그 외로 긴급하게 처리해야하는 작업을 실행해야 할 경우 Real-time Scheduling을 사용
	* 실시간 스케쥴링 (FIFO), Round Robin 스케쥴링을 제공함
* 프로세스의 우선순위 : nice값으로 설정되며 (-20 ~ 19) 사이의 값을 가지게 됨
	* 우선순위가 높을 수록 빨리 실행됨

* short-term : CPU가 다음 실행할 프로세스를 선정하는 것 , 스케쥴링이 자주 일어남
* mid-term: swap메모리에 있는 중단된 프로세스가 메인 메모리로 불러올 때 사용하는 스케쥴링. 그 반대인가?
* long-term: job-pool에 프로세스를 실행하는 상태로 변환하기 위해 사용하는 스케쥴링
* https://blogs.oracle.com/linux/post/task-priority

**프로세스의 상태**
* 생성
* 준비
* 실행
* 대기
* 종료

**프로세스 스케줄링 기법**
* 선점형 스케쥴링 : CPU가 우선순위가 높은 프로세스를 실행하기 위해 현재의 프로세스를 중단하고 CPU를 점유하는 스케쥴링 
	 * 우선순위 스케쥴링
	 * RR
	 * CFS

* 비선점형 스케쥴링 : 프로세스 작업을 다 처리할때까지 CPU를 점유하는 스케쥴링
	 * FCFS
	 * SJF

**동기와 비동기**
	* 작업을 순서대로 처리
	* 순서 상관 없이 동시에 처리

**프로세스(스레드) 동기화**
* Critical Section

**데드락**
* 각 프로세스 혹은 스레드가 갖고 있는 자원을 해제하지 못하는 상태에서 서로 자원 접근을 요청해 무한 대기가 발생하는 상태
* 데드락이 걸려야 하는 필요조건은 4가지다
	* 상호 배제
	* 점유 대기
	* 비선점
	* 순환대기
* 자원 할당 자체를 피하는 방법 : 뱅커스알고리즘 ㄱㄱ


--- 
## 2주차
#### 메모리 주소 바인딩
논리적 주소를 물리적 주소로 변환해주는 걸 말함

####  Swapping

주기억장치의 용량이 가득찰 경우 보조기억장치 공간을 이용하여 실행중인 프로세스를 관리하는 방법이다. 두가지로 구분된다.
* swap-in : 주기억장치에서 보조기억장치로 프로세스 정보가 이동하는 것
* swap-out : 보조기억장치에서 주기억장치로 프로세스 정보가 이동하는 것

##### 스와핑 과정
주기억장치에는 있지만 현재 실행하고 있지 않은 프로세스를 선택한 뒤 보조기억장치로 이동시키고, 보조기억장치에선 실행될 프로세스를 로드하여 실행하는 것을 반복한다.

#### 메모리 단편화

주기억장치의 메모리 공간이 할당 되거나 해제 되면서 사용 가능한 공간들이 쪼개지는 현상. 이 현상으로 인해 총 사용가능한 메모리 용량이 충분해도 프로그램을 실행할 수 없는 현상이 발생함 

단편화에는 2가지 종류가 있음
* 내부 단편화: 메모리 할당 단위가 실행에 필요한 프로세스 메모리보다 클 때 발생하는 빈공간
* 외부 단편화: 자주 일어나는 스와핑으로 인해 불 연속적인 빈공간이 발생하여 프로세스를 올리지 못하는 현상

#### 페이징

메모리 단편화를 해결하기 위한 방법 중 하나. 메모리를 일정 단위(페이지)로 나눈 후 페이징 테이블에 프로세스 논리 주소와 물리 주소를 매핑하여 외부 단편화를 해결한다. 그러나 페이지 단위보다 작은 프로세스가 실행될 경우 여전히 내부 단편화는 발생할 수 있다.

#### 세그멘테이션

세그맨테이션은 메모리를 일정 단위로 나누는 것이 아닌 base와 limit정보를 바탕으로 메모리 공간을 할당하는 방식을 의미함 base와 limit정보는 세그멘테이션 테이블에서 관리하고 각 프로세스는 고정된 페이지 와 달리 크기가 서로 다른 메모리 공간을 여러 공간에 흩어져 저장하게 됨. 내부 단편화 문제는 해결할 수 있지만 외부 단편화 문제가 남아있음

#### 세그멘테이션-페이징 혼합

세그맨테이션의 외부 단편화 문제와 페이징의 내부 단편화 문제를 해결하기위해 세그맨테이션 내부에서 일정한 크기의 테이블을 나뉘어 관리하기도 함. 이 경우에는 메모리 바인딩 과정에서 세그맨테이션의 base 주소를 얻은 후 몇 번째 페이지에 있는지까지 계산하는 방식으로 메모리에 있는 데이터를 접근한다고 한다.

#### 가상 메모리

주기억장치의공간보다 더 큰 크기의 데이터를 불러오기 위해 가상 메모리 기법을 사용함.
각 프로세스는 실제 물리주소에 접근하지 않고 가상 메모리 주소에 접근함.
가상 메모리 공간에 접근하기 때문에 프로세스끼리 메모리 주소가 충돌 날 걱정은 없음. 
가상 메모리는 일정한 단위 크기의 페이지(page)로 나뉘어저 있다고 함.
운영체제는 MMU이 관리하고 있는 페이지 테이블을 이용하여 각 페이지가 어느 프레임(물리 주소의 단위)에 위치되어있는지 확인할 수 있음

#### Page Fault(페이지 부재)

가상메모리를 이용해 운영하는 프로세스가 필요한 페이지를 불러올 때 해당 페이지가 존재하지 않아 발생할 수 있는 문제. 페이지 부재가 발생 시 페이지 교체 알고리즘에 따라 필요한 페이지를 불러오고 해당 데이터를 읽음. 당연히 필요한 페이지가 존재하지 않으니 교체할때까지 실행중인 프로세스는 멈춰있음. 

####  페이지 교체

페이지를 교체할 때 사용하는 방식임
FIFO : 가장 먼저 들어온 페이지 교체 - 페이지가 오래되었다는 이유만으로 교체될 수 있음
LRU : 가장 오랫동안 사용되지 않은 페이지 교체 - 사용되지 않은 시간을 재야하는 단점 존재
LFU : 가장 적게 사용된  페이지 교체 - 빈도수가 불규칙적인 페이지가 비효율적으로 남을 수 있음
Second Chance : FIFO에 참조 비트를 추가하여 참조되지 않은 페이지만 교체하는 알고리즘 : 참조비트로 인해 오버헤드가 발생할 수 있음
NRU, MFU

#### Thrashing

CPU가 프로세스 실행 보다 페이지 부제를 처리하는 데 시간을 많이 쏟는 걸 의미함

####  파일 시스템

데이터를 저장하고 관리하는 방식을 의미함 FAT, NTFS, ext3, ext4 

#### 디스크 블록 할당 방법
* 연속 할당 : 디스크를 쓰는 순서대로 할당하는 방법
* 연결 할당 : 연속 할당의 문제점인 단편화 문제를 해결하기 위해 다음 읽어야 할 디스크 주소를 기록함
* 인덱스 할당 : 디스크 앞에 색인 정보(index)를 저장하여 빠르게 접근하는 방식

#### 캐시의 지역성
* 시간 지역성 : 자주 사용하는 캐시 데이터는 자주 사용됨
* 공간 지역성 : 배열과 같은 연속된 데이터 중 한 곳을 참조할 경우 주변의 다른 데이터들도 자주 참조될 확률이 높아지는 것을 의미 / 특정 데이터를 포함하는 묶음 데이터를 추가로 로드하여 성능을 최적화 할 수 있음
* 순차적 지역성 : 순차적으로 탐색할 확률이 높은 데이터를 한 번에 올려서 캐싱할 수 있음
#### 캐싱 라인
캐싱의 효율을 높이기 위해 캐시 메모리에 한 번에 불러올 데이터의 최소 단위 : 32 bit에서 128bit라고 한다.